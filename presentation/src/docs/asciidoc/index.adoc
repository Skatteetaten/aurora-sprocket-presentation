:customcss: css/custom.css

There is a new CVE out... Critical vulnerability in your base image. We need to update everything now. How long will it take?
Hold my coffee, uhm ok I only need to update the version of our base and it is fixed. No problem. Git commit.
Can you approve the PR and everything will roll out?
*Yawn* No need, let me read the CVE and fix it, everything else will just happen automagically.

[state=title]
= Continuous deployment of docker images on Kubernetes that scale
Bjarte Stien Karlsen & Kristoffer Moberg Christensen
2019-09-14
:revnumber: {project-version}


[.image-slide]
[state=right-box]
== How do [.underline]#*YOU*# roll out critical security patches?
image::images/security-bug.jpg[canvas, size=cover]
[.credit]
credit:foobar

[state=red-font]
== Intro?
* Bjarte Stien Karlsen, Architect & Developer in the Norwegian Tax Administration(NTA)
* Kristoffer Moberg Christensen, Trainee in NTA

[state=red-font]
== Agenda
* Introduction ? 5 min
* Background 10 min
* Sprocket 15 min
* Use cases 10 min
* How can you adopt Sprocket? : 10 min
* How to expand on Sprocket? : 10 min

=== Last years problem
 * ImageStreams do not scale for _our_ needs
 * We have over 2000 unique ImageStreams and in _sometimes_ it takes hours! to roll out a new change
 ** Developers start to just manually roll out and not wait for it to happen automatically

[state=red-font]
== Background
 * Current solution based on polling the DockerRegistry
 * Part of the OpenShift distribution

=== Updating what is running
 * Scheduled ImageStreams
 * TODO: diagram ImageStream/Dc/DockerRegistry

=== Triggering builds
 * TODO: Diagram buildConfig trigger
 ** BuildTriggers on BaseImages and BuilderLogic

Bilder problemer

=== Problem #1: Performance
Polling for new changes to lots of images all the time does not scale

** TODO: Tall, logger. høre med Eivind/Siggen.

MaxScheduledImageImportsPerMinute=120
ScheduledImageImportMinimumIntervalSeconds=120

=== Problem #2: Race condition on multiple triggers
If a Pod has two containers and both have new versions who triggers first?

=== Problem #3: No flow control
Updating the base image/builder will fire every single build at the same time

=== Needs
 * push based, reacting to events/webhooks
 * support Nexus (hosted/grouped repos)
 * enable flow control

=== Can OpenSource help?
 * looked at a lot of alternatives
 * most are based on polling
 * most promising is https://keel.sh/docs/#introduction[keel]
 ** supports WebHook/push based
 ** does not support OpenShift resources
 ** does not support Nexus Container Registry
 ** no flow control

=== What primitives can help us here?
 * notifications from DockerRegistries
 * notifications from build pipelines

=== Build our own
 * No OpenSource solution so we decided to build our own based on notifications from Nexus Container Registry notifications
 * Current solution ties us to OpenShift

[state=left-box]
== Sprocket
image::images/sprocket.jpg[canvas, size=cover]
[.credit]
credit:https://barkpost.com/cute/the-best-muppet-dogs/

[state=red-font]
== Sprocket MVP
plantuml::sprocket.puml["sprocket", png]

=== Facts
* Currently running as a Pilot in our Platform
* Sprocket is named after the dog in Fraggle Rock

=== Limitations
 * no resilience if event fails
 ** we get an alert from Nexus but nothing automatic
 * only support a single cluster
 * no flow control
 * only support deploy on OpenShift via ImageStream

=== Sequence
 * listen to globalEventHook
 * filter out garbage events
 * parse event into a ImageChangeEvent(s)
 ** one hosted registry can have several groups so it can fire multiple events
 * find related kubernetes resources
 * perform builds/deployments/imports

=== Demo
 * show a video of how Sprocket works
 * building a new image will trigger a deploy on an event

=== Video manus
 - 3 terminaler
 - topp bygg
 - venstre sprocket log
 - høyre: stern for apper

 * start bygg uten sprocket annotasjon
 * vis at det kommer sprocket event men ikke at det rulles ut noe

 * annoter app 1
 * start bygg, vis at det kommer
 * annoter app 2
 * start bygg, vis at begge kommer


=== How do you use Sprocket
 * a single trigger in a resource can use the `skatteetaten.no/sprocket` label

=== Permissions
 - list ImageStream, perform ImageStreamUpdate
 - list, patch Deployment
 - list, rollout DeploymentConfig
 - list BuildConfig, start Build
 - list Sprocket

=== Plans
 * rate limiting
 ** label-name: skatteetaten.no/sprocket
 ** rate limit for type of event/action. Only run 100 builds then wait 5 sec
 * avoid duplicate rollouts from a single source
 * distributing ImageChangeEvent to multiple clusters
 * audit logging
 * fallback mechanism that can periodically poll and fire ImageChangeEvent
 * cache part of DockerManifest when an ImageChangeEvent happends

[state=red-font]
== Docker Registry

* Webhook pushes events to Sprocket
* Image

[state=red-font]
== Permissions

* Deployment

[state=red-font]
== Image Change

* Sprocket label on resources that wants updated images
* SHA1 hash of the image pull url
* Many-to-one semantics with CRD

==

[state=red-font]
== Usecases
How you can use Sprocket is correlated heavily on how you version your docker images. Does the version change if you change the way you build Docker Images or if the base image changes?

[state=red-font]
=== Our version strategy
https://skatteetaten.github.io/aurora/documentation/openshift/#image-versioning-strategy-the-auroraversion

* example from postgresql dockerhub. Screenshot?
* (Should be elaborated)

[state=red-font]
== Image change triggers
Pushing several tags for the same image allows user to decide when to update the deployment

[state=red-font]
== How can you adopt Sprocket?
* In your build pipeline push to a tag that is updated when there are new versions released on this release track.
* In your Deployments listen to this moveable tag and not an immutable tag
* label your Deployment with an sprocket label that is the hash of the URL to this tag.
* run sprocket configured to listen to Deployments in this namespace(or all namespaces)

[state=red-font]
== How to expand on Sprocket?
* Rate limit changes for one image
* Invalidate manifest cache
* support 1-many triggers via a CRD Sprocket.
* this will enable you to _not_ touch Deployment/ImageStream/DeploymentConfig resources. Only the CRD.
